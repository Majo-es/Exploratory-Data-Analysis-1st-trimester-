{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYex0PdHgjHq5CVTvI3rZV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Análisis exploratorio de datos"],"metadata":{"id":"8lM9IeUGsNwm"}},{"cell_type":"markdown","source":["## Unidad 8: Balanceo de datos"],"metadata":{"id":"Eq4oAJVbsUbj"}},{"cell_type":"markdown","source":["**Índice**   \n","1. [Datos desbalanceados: definición y problemas asociados](#id1)\n","2. [Métricas para evaluar datos desbalanceados](#id2)\n","3. [Algoritmos de balanceo de datos: sobremuestreo y submuestreo, generación de muestras sintéticas](#id3)"],"metadata":{"id":"b2bMdbsktD-2"}},{"cell_type":"markdown","source":["### 1. Datos desbalanceados: definición y problemas asociados <a name=\"id1\"></a>\n","\n","\n","Nos encontramos con un problema de datos desbalanceados (no balanceados) cuando las clases o categorías que se están analizando no están representadas de manera equitativa en un conjunto de datos. Es decir, hay una clase de la variable con muchos ejemplos (entradas), y otra con pocos.\n","\n","Un ejemplo de esta situación es un dataset de transacciones, con una columna que indica si la transacción es un fraude o no. En una situación normal, el porcentaje de fraude es bajo, por lo tanto, a lo mejor solo tenemos un 5% de entradas que han sido fraude, y el resto (95%), no.\n","\n","Esta desigualdad en la representación de clases puede afectar negativamente el rendimiento de algunos algoritmos de machine learning, sobretodo si el objetivo es predecir las clases de la variable desbalanceada.\n","\n","Volviendo al ejemplo anterior, un modelo que predijera todas las transacciones como **no fraude**, podría ser considerado bueno si se evalúa con una métrica como la *accuracy*, ya que el 95% de las entradas estarían correctamente clasificadas. Por tanto, si tenemos datos no balanceados, es importante también escoger una métrica adecuada o mirarlas en conjunto.\n","\n","Por otro lado, el hecho de tener una clase con menos representación (la clase minoritaria) también dificulta su descripción, ya que tenemos menos ejemplos de ella."],"metadata":{"id":"Sj3XGLERtGpX"}},{"cell_type":"markdown","source":["### 2. Métricas para evaluar datos desbalanceados <a name=\"id2\"></a>\n","\n","Como se ha comentado, cuando trabajamos con datos desbalanceados tenemos que escoger las métricas adecuadas para evaluar nuestros modelos, para evitar sacar conclusiones erróneas de su rendimiento/resultado.\n","\n","La recomendación principal es mirar distintas métricas y sacar conclusiones teniendo en cuenta el conjunto de ellas:\n","\n","**Exactitud (Accuracy)**\n","\n","La accuracy mide la proporción de predicciones correctas en relación con el total de predicciones. Aunque es una métrica intuitiva, puede ser engañosa en datos desbalanceados, ya que puede ser alta simplemente prediciendo la clase mayoritaria.\n","\n","**Precisión**\n","\n","La precisión se calcula como la proporción de verdaderos positivos (elementos correctamente clasificados como positivos) respecto a la suma de verdaderos positivos y falsos positivos. Es útil cuando nos interesa reducir los falsos positivos.\n","\n","**Recall (Sensibilidad)**\n","\n","Recall se calcula como la proporción de verdaderos positivos respecto a la suma de verdaderos positivos y falsos negativos. Es útil cuando queremos identificar la mayoría de las instancias de la clase positiva, incluso a costa de obtener más falsos positivos.\n","\n","**F1-Score**\n","\n","El F1-Score es la media armónica de precisión y recall. Es útil cuando se busca un equilibrio entre precisión y recall. Es una métrica muy completa, y se usa generalmente para tener una buena visión general del rendimiento del modelo.\n","\n","\n","**Área bajo la Curva ROC (AUC-ROC)**\n","\n","La curva ROC y el área bajo la curva ROC (AUC-ROC) son métricas que evalúan la capacidad del modelo para discriminar entre clases. Pueden ser especialmente informativas en datos desbalanceados."],"metadata":{"id":"FQkWF_db5gX1"}},{"cell_type":"code","source":["# Vamos a generar datos ficticios para mirar el impacto\n","# de los datos no balanceados en las métricas\n","\n","# Cargamos las librerías necesarias\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","# Ejemplo de predicciones y valores reales\n","# Las predicciones son todo 1s\n","# Solo hay 2 elementos con 1 en los valores reales (datos no balanceados)\n","y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n","y_pred = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n","\n","# Calculamos la accuracy\n","accuracy = accuracy_score(y_true, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Calculamos la precisión\n","precision = precision_score(y_true, y_pred)\n","print(\"Precisión:\", precision)\n","\n","# Calculamos el recall\n","recall = recall_score(y_true, y_pred)\n","print(\"Recall:\", recall)\n","\n","# Calculamos el F1-Score\n","f1 = f1_score(y_true, y_pred)\n","print(\"F1-Score:\", f1)\n","\n","# Calculamos y mostramos la matriz de Confusión\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","print(\"Matriz de Confusión:\")\n","print(conf_matrix)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVNEW5EP6nlp","executionInfo":{"status":"ok","timestamp":1733057106759,"user_tz":-60,"elapsed":6784,"user":{"displayName":"Alexandra Abos","userId":"16361723788115646104"}},"outputId":"ae575d36-57fa-458f-bb03-389e1ed0e0f3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9\n","Precisión: 0.5\n","Recall: 0.5\n","F1-Score: 0.5\n","Matriz de Confusión:\n","[[17  1]\n"," [ 1  1]]\n"]}]},{"cell_type":"markdown","source":["En este ejemplo, tenemos 20 elementos, y de ellos solo 2 tiene valor 1. Por lo tanto, los datos estan desbalanceados y la categoría 1 es la clase minoritaria. Creamos unos valores de predicción que solo identifican correctamente uno de los dos elementos con valor 1. Al mirar la accuracy, podemos pensar que el modelo es muy bueno, ya que tiene un valor muy alto (0.9), sin embargo, cuando miramos las otras métricas podemos ver que los valores son bajos. Por lo tanto, el hecho de tener los datos no balanceados y solo mirar la accuracy podría llevarnos a considerar que el modelo es óptimo, cuando realmente su rendimiento a nivel de detectar los 1s es bastante bajo."],"metadata":{"id":"uqmb6r5T8aH9"}},{"cell_type":"markdown","source":["### 3. Algoritmos de balanceo de datos: sobremuestreo y submuestreo, generación de muestras sintéticas <a name=\"id3\"></a>\n","\n","Para tratar el problema de datos desbalanceados, existen varias técnicas de balanceo de datos que se pueden utilizar.\n","\n","**Sobremuestreo (Oversampling)**\n","Esta técnica consiste en aumentar el número de instancias de la clase minoritaria generando copias adicionales de las observaciones existentes o generando instancias sintéticas.\n","\n","**Submuestreo (Undersampling)**\n","Al contrario que el sobremuestreo, este método reduce el número de instancias de la clase mayoritaria eliminando algunas observaciones aleatorias."],"metadata":{"id":"K-OdAUv39MqW"}},{"cell_type":"markdown","source":["La eleccion de una técnica u otra depende principalmente del contexto y de las características de los datos.\n","\n","**Oversampling**\n","\n","- El oversampling puede ser beneficioso cuando no hay suficientes datos en la clase minoritaria para entrenar un modelo de manera efectiva. Generar instancias sintéticas o duplicar muestras existentes puede ayudar a equilibrar las clases.\n","\n","- Si la clase minoritaria tiene patrones complejos y el submuestreo podría llevar a la pérdida de información relevante, por lo tanto, es mejor usar el sobremuestreo.\n","\n","**Undersampling**\n","\n","- Si tienes suficientes datos, reducir la cantidad de instancias en la clase mayoritaria para mejorar el equilibrio (undersampling) es una técnica sencilla y eficaz.\n","\n","- Si la clase mayoritaria contiene instancias que son redundantes se pueden eliminar estos ejemplos y así mejorar la repartición de las clases.\n","\n","- El oversampling puede ser más costoso computacionalmente, especialmente si se generan instancias sintéticas. Si la eficiencia computacional es una consideración importante, el submuestreo puede ser mejor opción."],"metadata":{"id":"zjGl4VmJBxbY"}},{"cell_type":"markdown","source":["Las funciones para las técnicas de over y undersampling se pueden encontrar en la librería `imblearn`."],"metadata":{"id":"r2fsZY97DGVo"}},{"cell_type":"code","source":["# Oversampling\n","\n","# Importamos la función necesaria\n","from imblearn.over_sampling import RandomOverSampler\n","\n","# Nos permite contar de manera eficiente\n","from collections import Counter\n","\n","# Esta función descarga un dataset de ejemplo\n","# Con las características especificadas\n","from sklearn.datasets import make_classification\n","X, y = make_classification(\n","    n_classes=2, class_sep=2, weights=[0.1, 0.9],\n","    n_informative=3, n_redundant=1, flip_y=0,\n","    n_features=20, n_clusters_per_class=1,\n","    n_samples=1000, random_state=10)\n","\n","# Inicializamos la función oversampling\n","oversampler = RandomOverSampler(sampling_strategy='auto')\n","\n","# En este caso, se aplica la transformación tanto a las características (X)\n","# como a la variable a predecir (y)\n","X_oversampled, y_oversampled = oversampler.fit_resample(X, y)\n","\n","# Mostramos los resultados por pantalla\n","print('Distribución de la variable y original %s' % Counter(y))\n","print('Distribución de la variable y después del oversampling %s' % Counter(y_oversampled))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQjPf-1cDF7O","executionInfo":{"status":"ok","timestamp":1733057109519,"user_tz":-60,"elapsed":2765,"user":{"displayName":"Alexandra Abos","userId":"16361723788115646104"}},"outputId":"53772e2c-4105-45a1-a5bb-35888fda9368"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Distribución de la variable y original Counter({1: 900, 0: 100})\n","Distribución de la variable y después del oversampling Counter({0: 900, 1: 900})\n"]}]},{"cell_type":"code","source":["# Undersampling\n","\n","# Importamos la función necesaria\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","# Inicializamos la función undersampling\n","undersampler = RandomUnderSampler(sampling_strategy='auto')\n","\n","# En este caso, se aplica la transformación tanto a las características (X)\n","# como a la variable a predecir (y)\n","X_undersampled, y_undersampled = undersampler.fit_resample(X, y)\n","\n","# Mostramos los resultados por pantalla\n","print('Distribución de la variable y original %s' % Counter(y))\n","print('Distribución de la variable y después del undersampling %s' % Counter(y_undersampled))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLpiAR1NDTkp","executionInfo":{"status":"ok","timestamp":1733057109519,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alexandra Abos","userId":"16361723788115646104"}},"outputId":"195073c0-99c5-4cc4-e250-d0f7426db16c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Distribución de la variable y original Counter({1: 900, 0: 100})\n","Distribución de la variable y después del undersampling Counter({0: 100, 1: 100})\n"]}]},{"cell_type":"code","source":["# Generación de muestras aleatorias\n","\n","# Importamos la función necesaria\n","from imblearn.over_sampling import SMOTE\n","\n","# Inicializamos la función de SMOTE\n","smote = SMOTE(sampling_strategy='auto')\n","\n","# En este caso, se aplica la transformación tanto a las características (X)\n","# como a la variable a predecir (y)\n","X_smote, y_smote = smote.fit_resample(X, y)\n","\n","\n","# Mostramos los resultados por pantalla\n","print('Distribución de la variable y original %s' % Counter(y))\n","print('Distribución de la variable y después de la generación de muestras aleatorias %s' % Counter(y_smote))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nykST0nmDTo5","executionInfo":{"status":"ok","timestamp":1733057109519,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alexandra Abos","userId":"16361723788115646104"}},"outputId":"8dea197d-6e26-4eef-8a49-0bf7ea13d038"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Distribución de la variable y original Counter({1: 900, 0: 100})\n","Distribución de la variable y después de la generación de muestras aleatorias Counter({0: 900, 1: 900})\n"]}]}]}